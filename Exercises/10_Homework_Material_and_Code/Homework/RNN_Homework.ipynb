{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab3437cc",
   "metadata": {},
   "source": [
    "# Homework 10 - Recurrent Neural Networks\n",
    "## WS2022/2023\n",
    "\n",
    "We will use a pseudo-random number generator to set the values for the inputs and weight matrices. \n",
    "To make sure that we all will get the same results, we have to set a seed for the pseudo-random number generator. \n",
    "\n",
    "**DO NOT CHANGE THE SEED!**\n",
    "\n",
    "The seed will probably change from semester to semester. Please make sure that this is the notebook for the current semester!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d04aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this homework we only need numpy\n",
    "import numpy as np\n",
    "\n",
    "# Set the seed for the pseudo-random number generator. DO NOT CHANGE!\n",
    "seed = 2223"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e8ee02",
   "metadata": {},
   "source": [
    "# Forward pass for a simple RNN\n",
    "In this exercise you will write a Python function to evaluate the forward pass of a simple RNN with the following unfolded computation graph:\n",
    "\n",
    "![Simple RNN](images/simple_rnn.png)\n",
    "\n",
    "Write a Python function e.g. called $\\mathbf{Y} = sim\\_rnn(\\mathbf{h}_0, \\mathbf{X}, \\mathbf{W}, \\mathbf{U}, \\mathbf{V}, \\mathbf{b}, \\mathbf{v})$, that evaluates the forward pass of the RNN with the following equations:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{h}_t &= \\tanh(\\mathbf{W}\\mathbf{h}_{t-1} + \\mathbf{U}\\mathbf{x}_t + \\mathbf{b}) \\\\\n",
    "    \\mathbf{y}_t &= \\mathbf{V}\\mathbf{h}_t + \\mathbf{v}\n",
    "\\end{align*}\n",
    "\n",
    "The $i$-th row in the matrix $\\mathbf{X}$ corresponds to the input vector $\\mathbf{x}_i$ at time-step $i$.\n",
    "The function should return a matrix $\\mathbf{Y}$ where the $i$-th row contains the output at time-step $i$. \n",
    "\n",
    "All inputs into the function as well as the outputs are numpy arrays. $\\mathbf{X}$, $\\mathbf{W}$, $\\mathbf{U}$, $\\mathbf{V}$ are matrices and $\\mathbf{h}_0$, $\\mathbf{b}$, $\\mathbf{v}$ are vectors.\n",
    "\n",
    "You can use the following template for the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6076b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_rnn(\n",
    "    h_0: np.ndarray,\n",
    "    X: np.ndarray,\n",
    "    W: np.ndarray,\n",
    "    U: np.ndarray,\n",
    "    V: np.ndarray,\n",
    "    b: np.ndarray,\n",
    "    v: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Forward pass for the simple RNN\"\"\"\n",
    "    \n",
    "    # Do your calculations here\n",
    "    # Useing h_t = tanh(W*h_t-1 + U*X_t + b)\n",
    "    # and Y = V*h_t + v\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    h_t = []\n",
    "    h_t.append(h_0)\n",
    "    for i in range(X.shape[0]):\n",
    "        h_t.append(np.tanh(np.matmul(W, h_t[i]) + np.matmul(U, X[i]) + b))\n",
    "    Y = []\n",
    "    for i in range(X.shape[0]):\n",
    "        Y.append(np.matmul(V, h_t[i+1]) + v)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ac777",
   "metadata": {},
   "source": [
    "Now, we create pseudo-random inputs, weight matrices and vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae873be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random_weights_rnn():\n",
    "    \"\"\"\n",
    "    Generate random weights\n",
    "    \n",
    "    DO NOT CHANGE!\n",
    "    \"\"\"\n",
    "    \n",
    "    # create pseudo-random number generator and set seed\n",
    "    prng = np.random.RandomState(seed)\n",
    "    \n",
    "    # random dimensions\n",
    "    n_h = int(prng.randint(2, 10, 1))  # the hidden state has a dimension between 2 and 10\n",
    "    n_x = int(prng.randint(50, 500, 1))  # one input vector has a dimension between 50 and 500\n",
    "    n_y = 2  # the output will have 2 dimensions\n",
    "\n",
    "    # number of steps\n",
    "    n_steps = 15  # the sequence will be 15 steps long\n",
    "\n",
    "    # initial hidden state\n",
    "    h_0 = prng.randn(n_h)\n",
    "\n",
    "    # input and weight matrices and bias vectors\n",
    "    X = prng.randn(n_steps, n_x)\n",
    "    W = prng.randn(n_h, n_h)\n",
    "    U = prng.randn(n_h, n_x)\n",
    "    b = prng.randn(n_h)\n",
    "    V = prng.randn(n_y, n_h)\n",
    "    v = prng.randn(n_y)\n",
    "    \n",
    "    return h_0, X, W, U, b, V, v\n",
    "\n",
    "h_0, X, W, U, b, V, v = gen_random_weights_rnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97451e7f",
   "metadata": {},
   "source": [
    "Use your function to calculate the output sequence and store it in the matrix $\\mathbf{Y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2bd6d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output time-step 1: [-2.91083062  0.82458322]\n",
      "Output time-step 2: [ 0.39076207 -1.92015393]\n",
      "Output time-step 3: [-2.27684388 -0.25243667]\n",
      "Output time-step 4: [-1.7454112   1.95794606]\n",
      "Output time-step 5: [ 2.04138548 -1.54670209]\n",
      "Output time-step 6: [-4.22587434  1.97787894]\n",
      "Output time-step 7: [ 0.11818177 -0.27242109]\n",
      "Output time-step 8: [-6.91640738  1.28664074]\n",
      "Output time-step 9: [ 2.49373692 -1.45286672]\n",
      "Output time-step 10: [-2.93165395  1.21415933]\n",
      "Output time-step 11: [-3.08335651  0.75229124]\n",
      "Output time-step 12: [-1.55755772  0.31089277]\n",
      "Output time-step 13: [ 1.91665606 -2.36142251]\n",
      "Output time-step 14: [ 0.11277131 -2.34545177]\n",
      "Output time-step 15: [-2.10131589  2.30990977]\n"
     ]
    }
   ],
   "source": [
    "Y = sim_rnn(h_0, X, W, U, V, b, v)\n",
    "\n",
    "for i, y_i in enumerate(Y, 1):\n",
    "    print(f\"Output time-step {i}: {y_i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e339c7d",
   "metadata": {},
   "source": [
    "Check for the requested time-step in the Moodle question and enter your result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bbcf31",
   "metadata": {},
   "source": [
    "# Forward pass for a bidirectional RNN\n",
    "In this exercise you will extend your function for the simple RNN, to also evaluate a backward sequence, resulting in the following bidirectional RNN:\n",
    "\n",
    "![Bidirectional RNN](images/bidirectional_rnn.png)\n",
    "\n",
    "Write a Python function e.g. called $\\mathbf{Y} = sim\\_bidir\\_rnn(\\mathbf{h}_0, \\mathbf{k}_T, \\mathbf{X}, \\mathbf{W}_1, \\mathbf{U}_1, \\mathbf{b}_1, \\mathbf{V}_1, \\mathbf{W}_2, \\mathbf{U}_2, \\mathbf{b}_2, \\mathbf{V}_2, \\mathbf{v})$, that evaluates the forward pass of the bidirectional RNN with the following equations:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{h}_t &= \\tanh(\\mathbf{W}_1\\mathbf{h}_{t-1} + \\mathbf{U}_1\\mathbf{x}_t + \\mathbf{b}_1) \\\\\n",
    "    \\mathbf{k}_t &= \\tanh(\\mathbf{W}_2\\mathbf{k}_{t+1} + \\mathbf{U}_2\\mathbf{x}_t + \\mathbf{b}_2) \\\\\n",
    "    \\mathbf{y}_t &= \\mathbf{V}_1\\mathbf{h}_t + \\mathbf{V}_2\\mathbf{k}_t + \\mathbf{v}\n",
    "\\end{align*}\n",
    "\n",
    "The $i$-th row in the matrix $\\mathbf{X}$ corresponds to the input vector $\\mathbf{x}_i$ at time-step $i$.\n",
    "The function should return a matrix $\\mathbf{Y}$ where the $i$-th row contains the output at time-step $i$. \n",
    "\n",
    "All inputs into the function as well as the outputs are numpy arrays. $\\mathbf{X}$, $\\mathbf{W}_1$, $\\mathbf{U}_1$, $\\mathbf{V}_1$, $\\mathbf{W}_2$, $\\mathbf{U}_2$, $\\mathbf{V}_21$ are matrices and $\\mathbf{h}_0$, $\\mathbf{k}_T$, $\\mathbf{b}_1$, $\\mathbf{b}_2$, $\\mathbf{v}$ are vectors. $\\mathbf{k}_T$ is similar to $\\mathbf{h}_0$, the initial guess for the second hidden state at the end of the sequence at time step $T$.\n",
    "\n",
    "You can use the following template for the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d97cb9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_bidir_rnn(\n",
    "    h_0: np.ndarray,\n",
    "    k_T: np.ndarray,\n",
    "    X: np.ndarray,\n",
    "    W_1: np.ndarray,\n",
    "    U_1: np.ndarray,\n",
    "    b_1: np.ndarray,\n",
    "    V_1: np.ndarray,\n",
    "    W_2: np.ndarray,\n",
    "    U_2: np.ndarray,\n",
    "    b_2: np.ndarray,\n",
    "    V_2: np.ndarray,\n",
    "    v: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Forward pass for the bidirectional RNN\"\"\"\n",
    "    \n",
    "    # Do your calculations here\n",
    "    # ....\n",
    "    # like in the previous task, but now you have to use two RNNs\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # h_t = tanh(W*h_t-1 + U*X_t + b)\n",
    "    # k_t = tanh(W*k_t+1 + U*X_t + b)\n",
    "    # Y = V*h_t + V*k_t + v\n",
    "    # forward pass\n",
    "    \n",
    "    h_t = []\n",
    "    h_t.append(h_0)\n",
    "    for i in range(X.shape[0]):\n",
    "        h_t.append(np.tanh(np.matmul(W_1, h_t[i]) + np.matmul(U_1, X[i]) + b_1))\n",
    "    Y = []\n",
    "    for i in range(X.shape[0]):\n",
    "        Y.append(np.matmul(V_1, h_t[i+1]))\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    # backward pass\n",
    "    k_T = np.tanh(np.matmul(W_2, k_T) + np.matmul(U_2, X[-1]) + b_2)\n",
    "    for i in range(X.shape[0]-1, -1, -1):\n",
    "        Y[i] = Y[i] + np.matmul(V_2, k_T) + v\n",
    "        k_T = np.tanh(np.matmul(W_2, k_T) + np.matmul(U_2, X[i-1]) + b_2)\n",
    "    \n",
    "    return Y\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c67eff",
   "metadata": {},
   "source": [
    "Now, we create pseudo-random inputs, weight matrices and vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2578288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random_weights_bidir_rnn():\n",
    "    \"\"\"\n",
    "    Generate random weights\n",
    "    \n",
    "    DO NOT CHANGE!\n",
    "    \"\"\"\n",
    "    \n",
    "    # create pseudo-random number generator and set seed\n",
    "    prng = np.random.RandomState(seed)\n",
    "    \n",
    "    # random dimensions\n",
    "    n_h = int(prng.randint(2, 10, 1))  # the hidden state h has a dimension between 2 and 10\n",
    "    n_k = int(prng.randint(3, 7, 1))  # the hidden state k has a dimension between 3 and 7\n",
    "    n_x = int(prng.randint(50, 500, 1))  # one input vector has a dimension between 50 and 500\n",
    "    n_y = 2  # the output will have 2 dimensions\n",
    "\n",
    "    # number of steps\n",
    "    n_steps = 15  # the sequence will be 15 steps long\n",
    "\n",
    "    # initial hidden states\n",
    "    h_0 = prng.randn(n_h)\n",
    "    k_T = prng.randn(n_k)\n",
    "\n",
    "\n",
    "    # input and weight matrices and bias vectors\n",
    "    X = prng.randn(n_steps, n_x)\n",
    "    W_1 = prng.randn(n_h, n_h)\n",
    "    U_1 = prng.randn(n_h, n_x)\n",
    "    b_1 = prng.randn(n_h)\n",
    "    V_1 = prng.randn(n_y, n_h)\n",
    "    \n",
    "    W_2 = prng.randn(n_k, n_k)\n",
    "    U_2 = prng.randn(n_k, n_x)\n",
    "    b_2 = prng.randn(n_k)\n",
    "    V_2 = prng.randn(n_y, n_k)\n",
    "    \n",
    "    v = prng.randn(n_y)\n",
    "    \n",
    "    return h_0, k_T, X, W_1, U_1, b_1, V_1, W_2, U_2, b_2, V_2, v\n",
    "\n",
    "h_0, k_T, X, W_1, U_1, b_1, V_1, W_2, U_2, b_2, V_2, v = gen_random_weights_bidir_rnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc64bb",
   "metadata": {},
   "source": [
    "Use your function to calculate the output sequence and store it in the matrix $\\mathbf{Y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "310ed029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output time-step 1: [-0.43492241 -3.48599326]\n",
      "Output time-step 2: [-1.40403368  8.29954021]\n",
      "Output time-step 3: [0.66625303 0.64616938]\n",
      "Output time-step 4: [ 0.21723953 -6.3092795 ]\n",
      "Output time-step 5: [-2.75393301 -5.08034158]\n",
      "Output time-step 6: [ 0.65424044 -3.35830087]\n",
      "Output time-step 7: [ 0.29827632 -5.04194486]\n",
      "Output time-step 8: [ 2.22499669 -0.66689858]\n",
      "Output time-step 9: [ 2.55412834 -1.36850835]\n",
      "Output time-step 10: [ 2.19833474 -7.33828425]\n",
      "Output time-step 11: [ 2.01731224 -2.19435422]\n",
      "Output time-step 12: [1.14792837 0.33398065]\n",
      "Output time-step 13: [ 1.29436457 -0.50772499]\n",
      "Output time-step 14: [ 2.02310537 -2.64353496]\n",
      "Output time-step 15: [-2.61262749  3.67937708]\n"
     ]
    }
   ],
   "source": [
    "Y = sim_bidir_rnn(h_0, k_T, X, W_1, U_1, b_1, V_1, W_2, U_2, b_2, V_2, v)\n",
    "\n",
    "for i, y_i in enumerate(Y, 1):\n",
    "    print(f\"Output time-step {i}: {y_i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6b788a",
   "metadata": {},
   "source": [
    "Check for the requested time-step in the Moodle question and enter your result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9aff9e50adfaa9e30c910fb3872ffdc72747acb5f50803ca0504f00e980f7c25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
